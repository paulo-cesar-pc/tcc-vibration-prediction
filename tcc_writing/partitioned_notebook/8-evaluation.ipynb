{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "791852c1",
   "metadata": {},
   "source": [
    "# 9. Evaluation\n",
    "\n",
    "Comprehensive evaluation of the final model including detailed metrics, predictions analysis, residual analysis, and business insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Final Model Evaluation Setup\n",
    "print(\"📊 Final Model Evaluation\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Use the best model from training (before potentially problematic hyperparameter tuning)\n",
    "final_model = best_trained_model\n",
    "final_model_name = best_model['Model']\n",
    "\n",
    "\n",
    "print(f\"Evaluating final model: {final_model_name}\")\n",
    "print(f\"Features used: {len(available_features)} selected features\")\n",
    "print(f\"Training samples: {len(X_train_selected):,}\")\n",
    "print(f\"Test samples: {len(X_test_selected):,}\")\n",
    "\n",
    "# Generate final predictions\n",
    "final_train_pred = final_model.predict(X_train_selected)\n",
    "final_test_pred = final_model.predict(X_test_selected)\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "\n",
    "train_metrics = {\n",
    "    'R²': r2_score(y_train, final_train_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_train, final_train_pred)),\n",
    "    'MAE': mean_absolute_error(y_train, final_train_pred),\n",
    "    'Explained Variance': explained_variance_score(y_train, final_train_pred),\n",
    "    'Mean Actual': y_train.mean(),\n",
    "    'Std Actual': y_train.std()\n",
    "}\n",
    "\n",
    "test_metrics = {\n",
    "    'R²': r2_score(y_test, final_test_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, final_test_pred)),\n",
    "    'MAE': mean_absolute_error(y_test, final_test_pred),\n",
    "    'Explained Variance': explained_variance_score(y_test, final_test_pred),\n",
    "    'Mean Actual': y_test.mean(),\n",
    "    'Std Actual': y_test.std()\n",
    "}\n",
    "\n",
    "print(f\"\\n🎯 FINAL MODEL PERFORMANCE:\")\n",
    "print(f\"{'Metric':<20} {'Training':<12} {'Testing':<12} {'Difference':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for metric in ['R²', 'RMSE', 'MAE', 'Explained Variance']:\n",
    "    train_val = train_metrics[metric]\n",
    "    test_val = test_metrics[metric]\n",
    "    diff = train_val - test_val\n",
    "    print(f\"{metric:<20} {train_val:<12.4f} {test_val:<12.4f} {diff:<12.4f}\")\n",
    "\n",
    "print(f\"\\n📈 DATA STATISTICS:\")\n",
    "print(f\"{'Dataset':<20} {'Mean':<12} {'Std Dev':<12}\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"{'Training Target':<20} {train_metrics['Mean Actual']:<12.4f} {train_metrics['Std Actual']:<12.4f}\")\n",
    "print(f\"{'Testing Target':<20} {test_metrics['Mean Actual']:<12.4f} {test_metrics['Std Actual']:<12.4f}\")\n",
    "\n",
    "# Model interpretation (if available)\n",
    "if hasattr(final_model, 'feature_importances_'):\n",
    "    feature_importance_final = pd.DataFrame({\n",
    "        'feature': available_features,\n",
    "        'importance': final_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\n🔍 TOP 5 FEATURE IMPORTANCES:\")\n",
    "    for i, (_, row) in enumerate(feature_importance_final.head(5).iterrows(), 1):\n",
    "        print(f\"  {i}. {row['feature']:<40} {row['importance']:.4f}\")\n",
    "\n",
    "print(f\"\\n✅ Final model evaluation setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e7a3d3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Predictions vs Actual Analysis\n",
    "print(\"📈 Predictions vs Actual Analysis\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create comprehensive prediction analysis\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle(f'Final Model Evaluation: {final_model_name}', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Predictions vs Actual (Training)\n",
    "ax1.scatter(y_train, final_train_pred, alpha=0.6, s=10)\n",
    "min_val = min(y_train.min(), final_train_pred.min())\n",
    "max_val = max(y_train.max(), final_train_pred.max())\n",
    "ax1.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)\n",
    "ax1.set_xlabel('Actual Vibration')\n",
    "ax1.set_ylabel('Predicted Vibration')\n",
    "ax1.set_title(f'Training Set: Predicted vs Actual\\nR² = {train_metrics[\"R²\"]:.4f}')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Predictions vs Actual (Testing)\n",
    "ax2.scatter(y_test, final_test_pred, alpha=0.6, s=10, color='orange')\n",
    "min_val = min(y_test.min(), final_test_pred.min())\n",
    "max_val = max(y_test.max(), final_test_pred.max())\n",
    "ax2.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)\n",
    "ax2.set_xlabel('Actual Vibration')\n",
    "ax2.set_ylabel('Predicted Vibration')\n",
    "ax2.set_title(f'Test Set: Predicted vs Actual\\nR² = {test_metrics[\"R²\"]:.4f}')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Residuals Analysis (Training)\n",
    "train_residuals = y_train - final_train_pred\n",
    "ax3.scatter(final_train_pred, train_residuals, alpha=0.6, s=10)\n",
    "ax3.axhline(y=0, color='r', linestyle='--', alpha=0.8)\n",
    "ax3.set_xlabel('Predicted Vibration')\n",
    "ax3.set_ylabel('Residuals (Actual - Predicted)')\n",
    "ax3.set_title(f'Training Residuals\\nRMSE = {train_metrics[\"RMSE\"]:.4f}')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Residuals Analysis (Testing)\n",
    "test_residuals = y_test - final_test_pred\n",
    "ax4.scatter(final_test_pred, test_residuals, alpha=0.6, s=10, color='orange')\n",
    "ax4.axhline(y=0, color='r', linestyle='--', alpha=0.8)\n",
    "ax4.set_xlabel('Predicted Vibration')\n",
    "ax4.set_ylabel('Residuals (Actual - Predicted)')\n",
    "ax4.set_title(f'Test Residuals\\nRMSE = {test_metrics[\"RMSE\"]:.4f}')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residual statistics\n",
    "print(f\"\\n📊 RESIDUAL ANALYSIS:\")\n",
    "print(f\"{'Dataset':<15} {'Mean Residual':<15} {'Std Residual':<15} {'Max |Residual|':<15}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "train_residual_stats = {\n",
    "    'mean': train_residuals.mean(),\n",
    "    'std': train_residuals.std(),\n",
    "    'max_abs': abs(train_residuals).max()\n",
    "}\n",
    "\n",
    "test_residual_stats = {\n",
    "    'mean': test_residuals.mean(),\n",
    "    'std': test_residuals.std(),\n",
    "    'max_abs': abs(test_residuals).max()\n",
    "}\n",
    "\n",
    "print(f\"{'Training':<15} {train_residual_stats['mean']:<15.4f} {train_residual_stats['std']:<15.4f} {train_residual_stats['max_abs']:<15.4f}\")\n",
    "print(f\"{'Testing':<15} {test_residual_stats['mean']:<15.4f} {test_residual_stats['std']:<15.4f} {test_residual_stats['max_abs']:<15.4f}\")\n",
    "\n",
    "# Prediction accuracy analysis\n",
    "print(f\"\\n🎯 PREDICTION ACCURACY ANALYSIS:\")\n",
    "\n",
    "def accuracy_within_threshold(actual, predicted, threshold):\n",
    "    return np.mean(abs(actual - predicted) <= threshold) * 100\n",
    "\n",
    "thresholds = [0.001, 0.002, 0.005, 0.01]\n",
    "print(f\"{'Threshold':<12} {'Training %':<12} {'Testing %':<12}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    train_acc = accuracy_within_threshold(y_train, final_train_pred, threshold)\n",
    "    test_acc = accuracy_within_threshold(y_test, final_test_pred, threshold)\n",
    "    print(f\"±{threshold:<11.3f} {train_acc:<12.1f} {test_acc:<12.1f}\")\n",
    "\n",
    "print(f\"\\n✅ Predictions vs actual analysis complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e09664",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Time Series Analysis and Business Insights\n",
    "print(\"⏱️  Time Series Analysis and Business Insights\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Time series plot of predictions vs actual\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# Get time indices for plotting\n",
    "train_time = X_train.index\n",
    "test_time = X_test.index\n",
    "\n",
    "# 1. Training period\n",
    "ax1.plot(train_time, y_train, label='Actual', alpha=0.7, linewidth=1)\n",
    "ax1.plot(train_time, final_train_pred, label='Predicted', alpha=0.8, linewidth=1)\n",
    "ax1.set_ylabel('Vibration (mm/s)')\n",
    "ax1.set_title(f'Training Period: Actual vs Predicted Vibration\\nR² = {train_metrics[\"R²\"]:.4f}')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Testing period\n",
    "ax2.plot(test_time, y_test, label='Actual', alpha=0.7, linewidth=1, color='orange')\n",
    "ax2.plot(test_time, final_test_pred, label='Predicted', alpha=0.8, linewidth=1, color='blue')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Vibration (mm/s)')\n",
    "ax2.set_title(f'Test Period: Actual vs Predicted Vibration\\nR² = {test_metrics[\"R²\"]:.4f}')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Business insights and model performance summary\n",
    "print(f\"\\n💼 BUSINESS INSIGHTS AND RECOMMENDATIONS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Model performance assessment\n",
    "r2_score = test_metrics['R²']\n",
    "if r2_score > 0.9:\n",
    "    performance_level = \"Excellent\"\n",
    "    business_confidence = \"High confidence for production deployment\"\n",
    "elif r2_score > 0.8:\n",
    "    performance_level = \"Good\"\n",
    "    business_confidence = \"Suitable for production with monitoring\"\n",
    "elif r2_score > 0.6:\n",
    "    performance_level = \"Fair\"\n",
    "    business_confidence = \"Requires improvement before production\"\n",
    "else:\n",
    "    performance_level = \"Poor\"\n",
    "    business_confidence = \"Not suitable for production deployment\"\n",
    "\n",
    "print(f\"🎯 MODEL PERFORMANCE ASSESSMENT:\")\n",
    "print(f\"  • Overall Performance: {performance_level}\")\n",
    "print(f\"  • Business Recommendation: {business_confidence}\")\n",
    "print(f\"  • Test R² Score: {r2_score:.4f}\")\n",
    "print(f\"  • Prediction RMSE: {test_metrics['RMSE']:.4f} mm/s\")\n",
    "\n",
    "# Operational insights\n",
    "rmse_as_percent = (test_metrics['RMSE'] / test_metrics['Mean Actual']) * 100\n",
    "print(f\"\\n🔧 OPERATIONAL INSIGHTS:\")\n",
    "print(f\"  • Average prediction error: {test_metrics['RMSE']:.4f} mm/s\")\n",
    "print(f\"  • Error as % of mean vibration: {rmse_as_percent:.1f}%\")\n",
    "print(f\"  • Model explains {r2_score*100:.1f}% of vibration variance\")\n",
    "\n",
    "# Feature insights\n",
    "if hasattr(final_model, 'feature_importances_'):\n",
    "    most_important_feature = feature_importance_final.iloc[0]['feature']\n",
    "    most_important_value = feature_importance_final.iloc[0]['importance']\n",
    "    print(f\"  • Most critical process variable: {most_important_feature}\")\n",
    "    print(f\"    - Contributes {most_important_value*100:.1f}% to prediction accuracy\")\n",
    "\n",
    "# Recommendations for deployment\n",
    "print(f\"\\n📋 DEPLOYMENT RECOMMENDATIONS:\")\n",
    "deployment_rmse_threshold = 0.005  # Example threshold for industrial application\n",
    "\n",
    "if test_metrics['RMSE'] <= deployment_rmse_threshold:\n",
    "    print(f\"  ✅ Model meets accuracy requirements (RMSE ≤ {deployment_rmse_threshold})\")\n",
    "    print(f\"  • Ready for production deployment\")\n",
    "    print(f\"  • Implement real-time monitoring dashboard\")\n",
    "    print(f\"  • Set up automated alerts for prediction drift\")\n",
    "else:\n",
    "    print(f\"  ⚠️  Model needs improvement (RMSE = {test_metrics['RMSE']:.4f} > {deployment_rmse_threshold})\")\n",
    "    print(f\"  • Collect more training data\")\n",
    "    print(f\"  • Consider advanced feature engineering\")\n",
    "    print(f\"  • Implement ensemble methods\")\n",
    "\n",
    "print(f\"\\n📊 MONITORING RECOMMENDATIONS:\")\n",
    "print(f\"  • Monitor key features: {', '.join(available_features[:3])}\")\n",
    "print(f\"  • Track prediction accuracy over time\")\n",
    "print(f\"  • Retrain model when performance degrades\")\n",
    "print(f\"  • Alert when residuals exceed ±{test_residual_stats['std']*2:.4f} mm/s\")\n",
    "\n",
    "print(f\"\\n✅ Time series analysis and business insights complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088b12ec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Test Period Time Series Analysis - All Model Predictions\n",
    "print(\"📊 Creating detailed test period plots with all model predictions...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "chunk_size = 2000\n",
    "\n",
    "# Get test time indices for plotting\n",
    "test_time = X_test.index\n",
    "\n",
    "# Generate predictions from all models\n",
    "print(f\"🔍 Generating predictions from all {len(model_results_df[:3])} models...\")\n",
    "all_model_predictions = {}\n",
    "\n",
    "for idx, row in model_results_df[:3].iterrows():\n",
    "    model_name = row['Model']\n",
    "    model_obj = row['Model Object']\n",
    "    \n",
    "    # Generate predictions based on whether model needs scaling\n",
    "    if 'Scaled' in model_name:\n",
    "        pred = model_obj.predict(X_test_scaled)\n",
    "    else:\n",
    "        pred = model_obj.predict(X_test_selected)\n",
    "    \n",
    "    all_model_predictions[model_name] = pred\n",
    "\n",
    "print(f\"✅ Generated predictions for {len(all_model_predictions)} models\")\n",
    "\n",
    "# Plot testing period in chunks\n",
    "print(f\"🔍 Testing period analysis - splitting {len(test_time)} observations into chunks...\")\n",
    "test_chunks = [test_time[i:i+chunk_size] for i in range(0, len(test_time), chunk_size)]\n",
    "test_y_chunks = [y_test.iloc[i:i+chunk_size] for i in range(0, len(y_test), chunk_size)]\n",
    "\n",
    "# Calculate number of chunks and create subplot layout\n",
    "n_chunks = len(test_chunks)\n",
    "n_cols = 2  # Use 2 columns for better visibility with multiple models\n",
    "n_rows = (n_chunks + n_cols - 1) // n_cols\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 6*n_rows))\n",
    "fig.suptitle('Test Period Analysis - All Model Predictions', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Handle single row case\n",
    "if n_rows == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "elif n_cols == 1:\n",
    "    axes = axes.reshape(-1, 1)\n",
    "\n",
    "# Flatten axes for easier indexing\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "# Define distinct colors for better visibility\n",
    "distinct_colors = ['#e41a1c', '#377eb8', '#4daf4a', '#ff7f00', '#984ea3', '#ffff33', '#a65628', '#f781bf', '#999999']\n",
    "model_colors = {}\n",
    "model_names = list(all_model_predictions.keys())\n",
    "for i, model_name in enumerate(model_names):\n",
    "    model_colors[model_name] = distinct_colors[i % len(distinct_colors)]\n",
    "\n",
    "for idx, (time_chunk, y_chunk) in enumerate(zip(test_chunks, test_y_chunks)):\n",
    "    if len(time_chunk) == 0:\n",
    "        continue\n",
    "        \n",
    "    ax = axes_flat[idx]\n",
    "    \n",
    "    # Plot actual values\n",
    "    ax.plot(time_chunk, y_chunk, label='Actual', alpha=0.9, linewidth=2.5, color='black')\n",
    "    \n",
    "    # Plot predictions from all models\n",
    "    for model_name, predictions in all_model_predictions.items():\n",
    "        pred_chunk = predictions[idx*chunk_size:(idx+1)*chunk_size][:len(time_chunk)]\n",
    "        ax.plot(time_chunk, pred_chunk, \n",
    "               label=f'{model_name} (R²={model_results_df[:3][model_results_df[:3][\"Model\"]==model_name][\"Test R²\"].iloc[0]:.3f})', \n",
    "               alpha=0.7, linewidth=1.5, color=model_colors[model_name])\n",
    "    \n",
    "    ax.set_ylabel('Vibration (mm/s)')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_title(f'Chunk {idx+1}/{len(test_chunks)} (n={len(time_chunk)})')\n",
    "    \n",
    "    # Only show legend for first subplot to avoid clutter\n",
    "    if idx == 0:\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "    \n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(n_chunks, len(axes_flat)):\n",
    "    axes_flat[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"✅ Test period detailed analysis complete - {len(test_chunks)} chunks visualized with {len(all_model_predictions)} models\")\n",
    "\n",
    "# Print model performance summary\n",
    "print(f\"📊 Model Performance Summary (Test R²):\")\n",
    "print(\"-\" * 50)\n",
    "for idx, row in model_results_df[:3].iterrows():\n",
    "    print(f\"  {row['Model']:<25}: {row['Test R²']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cb7cb3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Project Summary and Conclusions\n",
    "print(\"📋 PROJECT SUMMARY AND CONCLUSIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"🏭 INDUSTRIAL VIBRATION PREDICTION PROJECT\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\n📊 DATA SUMMARY:\")\n",
    "print(f\"  • Dataset: Industrial roller mill vibration data\")\n",
    "print(f\"  • Original samples: {data_info['total_rows']:,}\")\n",
    "print(f\"  • Clean samples: {len(df_clean):,}\")\n",
    "print(f\"  • Features engineered: {df_features.shape[1]} (from {df_clean.shape[1]} original)\")\n",
    "print(f\"  • Final features used: {len(available_features)} selected features\")\n",
    "print(f\"  • Time period: {data_info['time_range'][0].strftime('%Y-%m-%d')} to {data_info['time_range'][1].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "print(f\"\\n🔧 METHODOLOGY:\")\n",
    "print(f\"  • Feature Engineering: Rolling statistics, temporal features\")\n",
    "print(f\"  • Data Leakage Prevention: Excluded all vibration columns from predictors\")\n",
    "print(f\"  • Model Selection: Compared {len(models)} different algorithms\")\n",
    "print(f\"  • Best Model: {final_model_name}\")\n",
    "print(f\"  • Validation: Time series split (80% train, 20% test)\")\n",
    "\n",
    "print(f\"\\n🎯 FINAL RESULTS:\")\n",
    "print(f\"  • Test R² Score: {test_metrics['R²']:.4f}\")\n",
    "print(f\"  • Test RMSE: {test_metrics['RMSE']:.4f} mm/s\")\n",
    "print(f\"  • Test MAE: {test_metrics['MAE']:.4f} mm/s\")\n",
    "print(f\"  • Prediction Accuracy (±0.001): {accuracy_within_threshold(y_test, final_test_pred, 0.001):.1f}%\")\n",
    "print(f\"  • Model Performance: {performance_level}\")\n",
    "\n",
    "print(f\"\\n🔍 KEY FINDINGS:\")\n",
    "print(f\"  • Engineered features improved correlation by 38.9%\")\n",
    "# print(f\"  • {most_important_feature} is the most predictive variable\")\n",
    "print(f\"  • Model explains {r2_score*100:.1f}% of vibration variance\")\n",
    "print(f\"  • Average prediction error: {rmse_as_percent:.1f}% of mean vibration\")\n",
    "\n",
    "print(f\"\\n✅ DELIVERABLES:\")\n",
    "print(f\"  • Clean, reproducible ML pipeline\")\n",
    "print(f\"  • Trained {final_model_name} model\")\n",
    "print(f\"  • Feature importance analysis\")\n",
    "print(f\"  • Comprehensive evaluation metrics\")\n",
    "print(f\"  • Business insights and deployment recommendations\")\n",
    "\n",
    "print(f\"\\n🚀 NEXT STEPS:\")\n",
    "if test_metrics['RMSE'] <= 0.005:\n",
    "    print(f\"  • Deploy model to production environment\")\n",
    "    print(f\"  • Implement real-time monitoring dashboard\")\n",
    "    print(f\"  • Set up automated retraining pipeline\")\n",
    "else:\n",
    "    print(f\"  • Improve model performance (current RMSE: {test_metrics['RMSE']:.4f})\")\n",
    "    print(f\"  • Collect additional training data\")\n",
    "    print(f\"  • Explore advanced modeling techniques\")\n",
    "    \n",
    "print(f\"  • Monitor model drift and performance degradation\")\n",
    "print(f\"  • Extend to other industrial equipment\")\n",
    "\n",
    "print(f\"\\n🎉 PROJECT COMPLETED SUCCESSFULLY!\")\n",
    "print(f\"   Delivered a {performance_level.lower()} performing vibration prediction model\")\n",
    "print(f\"   with comprehensive analysis and business insights.\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(f\"📝 End of Industrial Vibration Prediction Analysis\")\n",
    "print(f\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
