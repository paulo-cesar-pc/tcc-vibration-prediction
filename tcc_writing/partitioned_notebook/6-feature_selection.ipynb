{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "049a7c8a",
   "metadata": {},
   "source": [
    "# 7. Feature Selection\n",
    "\n",
    "Based on the feature importance analysis, we'll select the most impactful features for model training. We'll use multiple selection strategies and compare their effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# First, prepare train/test split for feature selection\n",
    "print(\"=== PREPARING DATA FOR FEATURE SELECTION ===\")\n",
    "\n",
    "# Split the data first\n",
    "X_train, X_test, y_train, y_test = prepare_model_data(df_features, target_column, test_size=0.2)\n",
    "\n",
    "print(f\"✅ Data split complete:\")\n",
    "print(f\"  • Training samples: {len(X_train):,}\")\n",
    "print(f\"  • Testing samples: {len(X_test):,}\")\n",
    "print(f\"  • Total features: {X_train.shape[1]}\")\n",
    "\n",
    "# Apply different feature selection strategies\n",
    "print(\"\\n=== FEATURE SELECTION ANALYSIS ===\\n\")\n",
    "\n",
    "# Get feature names and prepare data\n",
    "feature_names = list(X_train.columns)\n",
    "print(f\"Total available features: {len(feature_names)}\")\n",
    "\n",
    "# Strategy 1: Top 20 features by importance\n",
    "top20_features, top20_indices = select_top_k_features(X_train, y_train, feature_names, k=20)\n",
    "print(f\"\\n1. TOP 20 FEATURES BY IMPORTANCE:\")\n",
    "for i, feature in enumerate(top20_features, 1):\n",
    "    print(f\"   {i:2d}. {feature}\")\n",
    "\n",
    "# Strategy 2: Features contributing to 80% cumulative importance\n",
    "cum80_features, cum80_indices = select_by_cumulative_importance(X_train, y_train, feature_names, threshold=0.8)\n",
    "print(f\"\\n2. FEATURES FOR 80% CUMULATIVE IMPORTANCE:\")\n",
    "print(f\"   Number of features needed: {len(cum80_features)}\")\n",
    "for i, feature in enumerate(cum80_features, 1):\n",
    "    print(f\"   {i:2d}. {feature}\")\n",
    "\n",
    "# Strategy 3: Features contributing to 90% cumulative importance  \n",
    "cum90_features, cum90_indices = select_by_cumulative_importance(X_train, y_train, feature_names, threshold=0.9)\n",
    "print(f\"\\n3. FEATURES FOR 90% CUMULATIVE IMPORTANCE:\")\n",
    "print(f\"   Number of features needed: {len(cum90_features)}\")\n",
    "\n",
    "# Strategy 4: Statistical feature selection (top 20)\n",
    "stat_features, stat_indices = select_statistical_features(X_train, y_train, feature_names, k=20)\n",
    "print(f\"\\n4. TOP 20 STATISTICAL FEATURES:\")\n",
    "for i, feature in enumerate(stat_features, 1):\n",
    "    print(f\"   {i:2d}. {feature}\")\n",
    "\n",
    "# Compare overlap between methods\n",
    "print(f\"\\n=== FEATURE SELECTION COMPARISON ===\")\n",
    "top20_set = set(top20_features)\n",
    "stat_set = set(stat_features)\n",
    "overlap = top20_set.intersection(stat_set)\n",
    "\n",
    "print(f\"Overlap between RF Importance and Statistical: {len(overlap)}/20 features\")\n",
    "print(f\"Common features: {sorted(list(overlap))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdac803",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare final selected features for next sections\n",
    "print(\"=== PREPARING SELECTED FEATURES FOR MODEL TRAINING ===\")\n",
    "\n",
    "# Use 80% cumulative importance as our selected feature set\n",
    "selected_features = cum80_features\n",
    "selected_feature_indices = cum80_indices\n",
    "\n",
    "# Create final training datasets with selected features\n",
    "X_train_selected = X_train.iloc[:, selected_feature_indices].copy()\n",
    "X_test_selected = X_test.iloc[:, selected_feature_indices].copy()\n",
    "\n",
    "print(f\"Original feature count: {X_train.shape[1]}\")\n",
    "print(f\"Selected feature count: {X_train_selected.shape[1]}\")\n",
    "print(f\"Feature reduction: {((X_train.shape[1] - X_train_selected.shape[1]) / X_train.shape[1] * 100):.1f}%\")\n",
    "\n",
    "print(f\"Training set shape: {X_train_selected.shape}\")\n",
    "print(f\"Test set shape: {X_test_selected.shape}\")\n",
    "\n",
    "print(f\"Selected features saved for model training phase:\")\n",
    "for i, feature in enumerate(selected_features, 1):\n",
    "    print(f\"  {i:2d}. {feature}\")\n",
    "\n",
    "# Verify no data leakage in selected features\n",
    "vibration_features = [f for f in selected_features if 'vibration' in f.lower() or 'vib' in f.lower()]\n",
    "if vibration_features:\n",
    "    print(f\"⚠️  WARNING: Found vibration-related features in selection: {vibration_features}\")\n",
    "else:\n",
    "    print(f\"✅ CONFIRMED: No vibration-related features in selected set - data leakage prevented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f9db19",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create different feature sets for model comparison\n",
    "feature_sets = {\n",
    "    'All Features': (list(range(len(feature_names))), len(feature_names)),\n",
    "    'Top 20 RF': (top20_indices, len(top20_features)),\n",
    "    'Top 20 Statistical': (stat_indices, len(stat_features)),\n",
    "    'Cumulative 80%': (cum80_indices, len(cum80_features)),\n",
    "    'Cumulative 90%': (cum90_indices, len(cum90_features))\n",
    "}\n",
    "\n",
    "print(\"=== FEATURE SET SUMMARY ===\")\n",
    "for name, (indices, count) in feature_sets.items():\n",
    "    print(f\"{name}: {count} features\")\n",
    "\n",
    "# Quick model performance comparison with different feature sets\n",
    "print(f\"\\n=== QUICK PERFORMANCE COMPARISON ===\")\n",
    "results = []\n",
    "\n",
    "for set_name, (indices, count) in feature_sets.items():\n",
    "    # Select features\n",
    "    X_train_subset = X_train.iloc[:, indices]\n",
    "    X_test_subset = X_test.iloc[:, indices]\n",
    "    \n",
    "    # Train simple model\n",
    "    rf_quick = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "    rf_quick.fit(X_train_subset, y_train)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    train_pred = rf_quick.predict(X_train_subset)\n",
    "    test_pred = rf_quick.predict(X_test_subset)\n",
    "    \n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    test_r2 = r2_score(y_test, test_pred)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n",
    "    \n",
    "    results.append({\n",
    "        'Feature Set': set_name,\n",
    "        'Features': count,\n",
    "        'Train R²': train_r2,\n",
    "        'Test R²': test_r2,\n",
    "        'Train RMSE': train_rmse,\n",
    "        'Test RMSE': test_rmse,\n",
    "        'Overfitting': train_r2 - test_r2\n",
    "    })\n",
    "    \n",
    "    print(f\"{set_name:15s} ({count:3d} features): R² = {test_r2:.4f}, RMSE = {test_rmse:.3f}\")\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\n=== DETAILED RESULTS ===\")\n",
    "print(results_df.round(4))\n",
    "\n",
    "# Visualize feature selection results\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Performance comparison\n",
    "performance_data = results_df[['Feature Set', 'Features', 'Test R²', 'Test RMSE']].copy()\n",
    "ax1.scatter(performance_data['Features'], performance_data['Test R²'], s=100, alpha=0.7)\n",
    "for i, row in performance_data.iterrows():\n",
    "    ax1.annotate(row['Feature Set'], \n",
    "                (row['Features'], row['Test R²']), \n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "ax1.set_xlabel('Number of Features')\n",
    "ax1.set_ylabel('Test R²')\n",
    "ax1.set_title('Feature Set Performance: R² vs Number of Features')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Overfitting analysis\n",
    "ax2.bar(results_df['Feature Set'], results_df['Overfitting'], alpha=0.7)\n",
    "ax2.set_xlabel('Feature Set')\n",
    "ax2.set_ylabel('Overfitting (Train R² - Test R²)')\n",
    "ax2.set_title('Overfitting Analysis by Feature Set')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Feature type distribution for selected sets\n",
    "feature_types = {'Rolling_Mean': [], 'Rolling_Std': [], 'Original': [], 'Temporal': []}\n",
    "\n",
    "for feature in cum80_features:  # Use 80% cumulative as example\n",
    "    if '_rolling_mean_' in feature:\n",
    "        feature_types['Rolling_Mean'].append(feature)\n",
    "    elif '_rolling_std_' in feature:\n",
    "        feature_types['Rolling_Std'].append(feature)\n",
    "    elif feature in ['hour', 'day_of_week', 'month']:\n",
    "        feature_types['Temporal'].append(feature)\n",
    "    else:\n",
    "        feature_types['Original'].append(feature)\n",
    "\n",
    "type_counts = [len(features) for features in feature_types.values()]\n",
    "ax3.pie(type_counts, labels=feature_types.keys(), autopct='%1.1f%%', startangle=90)\n",
    "ax3.set_title(f'Feature Type Distribution\\n(80% Cumulative Set - {len(cum80_features)} features)')\n",
    "\n",
    "# 4. Performance vs complexity tradeoff\n",
    "ax4.scatter(results_df['Features'], results_df['Test RMSE'], s=100, alpha=0.7, color='red')\n",
    "for i, row in results_df.iterrows():\n",
    "    ax4.annotate(row['Feature Set'], \n",
    "                (row['Features'], row['Test RMSE']), \n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "ax4.set_xlabel('Number of Features')\n",
    "ax4.set_ylabel('Test RMSE')\n",
    "ax4.set_title('Feature Set Performance: RMSE vs Number of Features')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Recommend optimal feature set\n",
    "print(\"\\n=== FEATURE SELECTION RECOMMENDATION ===\")\n",
    "best_r2 = results_df.loc[results_df['Test R²'].idxmax()]\n",
    "best_tradeoff = results_df.loc[(results_df['Test R²'] > 0.85) & (results_df['Features'] < 50)]\n",
    "if not best_tradeoff.empty:\n",
    "    best_tradeoff = best_tradeoff.loc[best_tradeoff['Features'].idxmin()]\n",
    "    print(f\"Recommended: {best_tradeoff['Feature Set']} ({best_tradeoff['Features']} features)\")\n",
    "    print(f\"  - Test R²: {best_tradeoff['Test R²']:.4f}\")\n",
    "    print(f\"  - Test RMSE: {best_tradeoff['Test RMSE']:.3f}\")\n",
    "    print(f\"  - Good balance of performance and complexity\")\n",
    "else:\n",
    "    print(f\"Best overall: {best_r2['Feature Set']} ({best_r2['Features']} features)\")\n",
    "    print(f\"  - Test R²: {best_r2['Test R²']:.4f}\")\n",
    "    print(f\"  - Test RMSE: {best_r2['Test RMSE']:.3f}\")\n",
    "\n",
    "print(f\"\\nFinal selected features for modeling: {best_r2['Feature Set']}\")\n",
    "print(f\"Features: {sorted(top20_features)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
