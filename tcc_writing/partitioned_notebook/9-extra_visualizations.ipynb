{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9cd9485",
   "metadata": {},
   "source": [
    "# 10. Visualizations\n",
    "\n",
    "**Purpose**: Create comprehensive visualizations for scientific paper publication including:\n",
    "- Target variable distribution analysis\n",
    "- Statistical summaries and normality testing\n",
    "- Outlier detection and visualization\n",
    "- Time series patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Enhanced Data Distribution Visualizations for Paper\n",
    "print(\"📊 Creating comprehensive data distribution visualizations\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set publication-quality matplotlib parameters\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 13\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "\n",
    "# 1. Target Variable Distribution Analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Vibration RMS Distribution Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Histogram with KDE and statistics\n",
    "target_data = df_raw[target_column]\n",
    "axes[0,0].hist(target_data, bins=50, alpha=0.7, density=True, color='steelblue', \n",
    "               edgecolor='black', linewidth=0.8)\n",
    "\n",
    "# Add KDE overlay\n",
    "from scipy.stats import gaussian_kde\n",
    "kde = gaussian_kde(target_data)\n",
    "x_range = np.linspace(target_data.min(), target_data.max(), 100)\n",
    "axes[0,0].plot(x_range, kde(x_range), 'red', linewidth=2, label='KDE')\n",
    "\n",
    "axes[0,0].set_title('A) Histogram with Kernel Density Estimate', fontweight='bold')\n",
    "axes[0,0].set_xlabel('Vibration RMS (mm/s)')\n",
    "axes[0,0].set_ylabel('Density')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Add comprehensive statistics\n",
    "mean_vib = target_data.mean()\n",
    "std_vib = target_data.std()\n",
    "median_vib = target_data.median()\n",
    "skew_vib = stats.skew(target_data)\n",
    "kurt_vib = stats.kurtosis(target_data)\n",
    "q25, q75 = np.percentile(target_data, [25, 75])\n",
    "\n",
    "stats_text = f'Mean: {mean_vib:.3f}\\nStd: {std_vib:.3f}\\nMedian: {median_vib:.3f}\\n'\n",
    "stats_text += f'Skewness: {skew_vib:.3f}\\nKurtosis: {kurt_vib:.3f}\\nIQR: {q25:.3f}-{q75:.3f}'\n",
    "\n",
    "axes[0,0].text(0.02, 0.98, stats_text, transform=axes[0,0].transAxes, \n",
    "               verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "\n",
    "# Box plot with outlier analysis and quartile labels\n",
    "box_plot = axes[0,1].boxplot(target_data, patch_artist=True, \n",
    "                            boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                            medianprops=dict(color='red', linewidth=2))\n",
    "axes[0,1].set_title('B) Box Plot with Outlier Detection', fontweight='bold')\n",
    "axes[0,1].set_ylabel('Vibration RMS (mm/s)')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add quartile annotations\n",
    "axes[0,1].text(1.1, q25, f'Q1: {q25:.3f}', va='center')\n",
    "axes[0,1].text(1.1, median_vib, f'Median: {median_vib:.3f}', va='center', weight='bold')\n",
    "axes[0,1].text(1.1, q75, f'Q3: {q75:.3f}', va='center')\n",
    "\n",
    "# Calculate and display outlier statistics\n",
    "iqr = q75 - q25\n",
    "lower_fence = q25 - 1.5 * iqr\n",
    "upper_fence = q75 + 1.5 * iqr\n",
    "outliers = target_data[(target_data < lower_fence) | (target_data > upper_fence)]\n",
    "outlier_pct = (len(outliers) / len(target_data)) * 100\n",
    "\n",
    "axes[0,1].text(0.5, 0.02, f'Outliers: {len(outliers)} ({outlier_pct:.1f}%)', \n",
    "               transform=axes[0,1].transAxes, ha='center',\n",
    "               bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "# Q-Q plot for normality assessment with correlation coefficient\n",
    "stats.probplot(target_data, dist=\"norm\", plot=axes[1,0])\n",
    "axes[1,0].set_title('C) Q-Q Plot: Normality Assessment', fontweight='bold')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Calculate normality test statistics\n",
    "shapiro_stat, shapiro_p = stats.shapiro(target_data.sample(min(5000, len(target_data))))\n",
    "ks_stat, ks_p = stats.kstest(target_data, 'norm', args=(mean_vib, std_vib))\n",
    "\n",
    "norm_text = f'Shapiro-Wilk: p={shapiro_p:.2e}\\nKS Test: p={ks_p:.2e}\\n'\n",
    "norm_text += 'Normal' if shapiro_p > 0.05 else 'Non-normal'\n",
    "\n",
    "axes[1,0].text(0.02, 0.98, norm_text, transform=axes[1,0].transAxes, \n",
    "               verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "\n",
    "# Time series with trend analysis\n",
    "time_index = range(len(target_data))\n",
    "axes[1,1].plot(time_index, target_data, alpha=0.6, linewidth=0.5, color='darkred', label='Vibration RMS')\n",
    "\n",
    "# Add moving average trend\n",
    "window_size = max(50, len(target_data) // 100)\n",
    "moving_avg = target_data.rolling(window=window_size, center=True).mean()\n",
    "axes[1,1].plot(time_index, moving_avg, color='blue', linewidth=2, label=f'Moving Avg ({window_size} points)')\n",
    "\n",
    "axes[1,1].set_title('D) Time Series with Trend Analysis', fontweight='bold')\n",
    "axes[1,1].set_xlabel('Time Index')\n",
    "axes[1,1].set_ylabel('Vibration RMS (mm/s)')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "axes[1,1].legend()\n",
    "\n",
    "# Add horizontal lines for statistical measures\n",
    "axes[1,1].axhline(y=mean_vib, color='green', linestyle='--', alpha=0.7, label='Mean')\n",
    "axes[1,1].axhline(y=median_vib, color='orange', linestyle='--', alpha=0.7, label='Median')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"✅ Target variable distribution analysis complete\")\n",
    "print(f\"📊 Data Summary: {len(target_data):,} samples, Range: {target_data.min():.3f}-{target_data.max():.3f} mm/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7266430a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Executive Summary Dashboard for Publication\n",
    "print(\"📋 Creating executive summary dashboard\")\n",
    "print(\"=\"*60)\n",
    "from scipy import stats\n",
    "\n",
    "# Create comprehensive summary visualization\n",
    "fig = plt.figure(figsize=(20, 14))\n",
    "gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Title\n",
    "fig.suptitle('Industrial Vibration Prediction: Executive Summary Dashboard', \n",
    "             fontsize=18, fontweight='bold', y=0.95)\n",
    "\n",
    "# 1. Model Performance Ranking (Top-left, 2x2)\n",
    "ax1 = fig.add_subplot(gs[0:2, 0:2])\n",
    "\n",
    "# Sort models by test R²\n",
    "if 'model_results' in locals():\n",
    "    results_df = model_results_df.sort_values('Test R²', ascending=True)\n",
    "else:\n",
    "    # Fallback if enhanced results not available\n",
    "    results_df = model_results_df.sort_values('Test R²', ascending=True)\n",
    "\n",
    "# Create horizontal bar chart\n",
    "models = results_df['Model'].values\n",
    "if 'Test R²' in df_raw.columns:\n",
    "    r2_scores = results_df['Test R²'].values\n",
    "else:\n",
    "    r2_scores = results_df['Test R²'].values\n",
    "\n",
    "# Color bars by performance\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.3, 1.0, len(models)))\n",
    "bars = ax1.barh(models, r2_scores, color=colors, alpha=0.8, edgecolor='black', linewidth=1)\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, score) in enumerate(zip(bars, r2_scores)):\n",
    "    width = bar.get_width()\n",
    "    ax1.text(width + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "             f'{score:.3f}', ha='left', va='center', fontweight='bold')\n",
    "\n",
    "ax1.set_xlabel('R² Score', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Model Performance Ranking', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "ax1.set_xlim(0, max(r2_scores) * 1.15)\n",
    "\n",
    "# Add performance categories\n",
    "best_score = max(r2_scores)\n",
    "ax1.axvline(x=best_score * 0.9, color='gold', linestyle='--', alpha=0.7, linewidth=2)\n",
    "ax1.text(best_score * 0.9, len(models) * 0.9, 'Excellent\\n(>90% of best)', \n",
    "         ha='center', va='center', bbox=dict(boxstyle='round', facecolor='gold', alpha=0.7))\n",
    "\n",
    "# 2. Data Quality Summary (Top-right)\n",
    "ax2 = fig.add_subplot(gs[0, 2:])\n",
    "\n",
    "# Data quality metrics\n",
    "data_quality = {\n",
    "    'Total Samples': len(df_raw),\n",
    "    'Features': len([col for col in df_raw.columns if col != target_column]),\n",
    "    'Missing Values': df_raw.isnull().sum().sum(),\n",
    "    'Outliers (±3σ)': len(df_raw[np.abs(df_raw[target_column] - df_raw[target_column].mean()) > 3 * df_raw[target_column].std()]),\n",
    "    'Data Range': f\"{df_raw[target_column].min():.2f} - {df_raw[target_column].max():.2f}\",\n",
    "    'Std Deviation': f\"{df_raw[target_column].std():.3f}\"\n",
    "}\n",
    "\n",
    "# Create text summary\n",
    "ax2.axis('off')\n",
    "summary_text = \"Data Quality Assessment\\n\" + \"=\"*25 + \"\\n\\n\"\n",
    "for key, value in data_quality.items():\n",
    "    summary_text += f\"• {key}: {value}\\n\"\n",
    "\n",
    "# Add data quality insights\n",
    "insights = [\n",
    "    f\"• Data completeness: {((len(df_raw) - df_raw.isnull().sum().sum()) / len(df_raw) * 100):.1f}%\",\n",
    "    f\"• Target variability: CV = {(df_raw[target_column].std() / df_raw[target_column].mean()) * 100:.1f}%\",\n",
    "    f\"• Signal-to-noise ratio: High\" if df_raw[target_column].std() > 0.1 else \"• Signal-to-noise ratio: Low\"\n",
    "]\n",
    "\n",
    "summary_text += \"\\nData Quality Score: \"\n",
    "quality_score = 100 - (df_raw.isnull().sum().sum() / len(df_raw) * 10) - (len(df_raw[np.abs(stats.zscore(df_raw[target_column])) > 3]) / len(df_raw) * 5)\n",
    "summary_text += f\"{quality_score:.0f}/100\"\n",
    "\n",
    "ax2.text(0.1, 0.9, summary_text, transform=ax2.transAxes, fontsize=11,\n",
    "         verticalalignment='top', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.3))\n",
    "\n",
    "# 3. Feature Importance Top 10 (Middle-right)\n",
    "ax3 = fig.add_subplot(gs[1, 2:])\n",
    "\n",
    "# Get feature importance from best model\n",
    "# Use Random Forest for feature importance (most interpretable)\n",
    "if 'model_results' in locals():\n",
    "    # Find Random Forest model for interpretability\n",
    "    rf_models = [r for r in model_results if 'Random Forest' in r['Model'] or 'Forest' in r['Model']]\n",
    "    if rf_models:\n",
    "        best_interpretable_model = max(rf_models, key=lambda x: x['Test R²'])\n",
    "        print(f\"Using {best_interpretable_model['Model']} for feature importance (R² = {best_interpretable_model['Test R²']:.4f})\")\n",
    "    else:\n",
    "        # Fallback: train a new Random Forest for feature importance\n",
    "        print(\"Training Random Forest for feature importance analysis...\")\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        rf_temp = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        # Use the same features as the manual selection\n",
    "        X_temp = df_raw[manual_selected_features].fillna(method='ffill').fillna(method='bfill')\n",
    "        y_temp = df_raw[target_column]\n",
    "        rf_temp.fit(X_temp, y_temp)\n",
    "        \n",
    "        # Create feature importance plot\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': manual_selected_features,\n",
    "            'importance': rf_temp.feature_importances_\n",
    "        }).sort_values('importance', ascending=True)\n",
    "else:\n",
    "    best_model_data = max(model_results, key=lambda x: x['Test R²'])\n",
    "    best_model = best_model_data['Model Object']\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    # Get actual feature names if available\n",
    "    if 'X_train_selected' in locals():\n",
    "        feature_names = X_train_selected.columns.tolist()\n",
    "    else:\n",
    "        feature_names = [f'Feature_{i}' for i in range(len(importance_df[\"importance\"].values))]\n",
    "    \n",
    "    df_raw = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importance_df[\"importance\"].values\n",
    "    }).sort_values('importance', ascending=True).tail(10)\n",
    "    \n",
    "    bars = ax3.barh(range(len(df_raw)), df_raw['importance'], \n",
    "                    color='green', alpha=0.7)\n",
    "    ax3.set_yticks(range(len(df_raw)))\n",
    "    ax3.set_yticklabels(df_raw['feature'])\n",
    "    ax3.set_xlabel('Importance Score')\n",
    "    ax3.set_title(f'Top 10 Features ({best_model_data[\"Model\"]})', fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3, axis='x')\n",
    "else:\n",
    "    ax3.text(0.5, 0.5, 'Feature importance\\nnot available for\\nbest performing model', \n",
    "             ha='center', va='center', transform=ax3.transAxes, fontsize=12)\n",
    "    ax3.set_title('Feature Importance: N/A', fontweight='bold')\n",
    "\n",
    "# 4. Performance Metrics Comparison Table (Bottom, full width)\n",
    "ax4 = fig.add_subplot(gs[2, :])\n",
    "ax4.axis('off')\n",
    "\n",
    "# Create comprehensive metrics table\n",
    "if 'model_results' in locals():\n",
    "    table_data = []\n",
    "    for result in model_results:\n",
    "        row = [\n",
    "            result['Model'],\n",
    "            f\"{result['Test R²']:.4f}\",\n",
    "            f\"{result['Test RMSE']:.4f}\",\n",
    "            f\"{result['Training Time']:.3f}s\"\n",
    "        ]\n",
    "        table_data.append(row)\n",
    "    \n",
    "    columns = ['Model', 'Test R²', 'Test RMSE', 'Training Time']\n",
    "else:\n",
    "    # Fallback table\n",
    "    table_data = []\n",
    "    for result in model_results:\n",
    "        row = [\n",
    "            result['Model'],\n",
    "            f\"{result['Test R²']:.4f}\",\n",
    "            f\"{result['Test RMSE']:.4f}\",\n",
    "            f\"{result['Train R²']:.4f}\",\n",
    "            f\"{result['Training Time']:.3f}s\"\n",
    "        ]\n",
    "        table_data.append(row)\n",
    "    \n",
    "    columns = ['Model', 'Test R²', 'Test RMSE', 'Train R²', 'Training Time']\n",
    "\n",
    "# Sort by Test R² (descending)\n",
    "if 'model_results' in locals():\n",
    "    table_data = sorted(table_data, key=lambda x: float(x[1]), reverse=True)\n",
    "else:\n",
    "    table_data = sorted(table_data, key=lambda x: float(x[1]), reverse=True)\n",
    "\n",
    "# Create table\n",
    "table = ax4.table(cellText=table_data, colLabels=columns, \n",
    "                  cellLoc='center', loc='center',\n",
    "                  bbox=[0, 0, 1, 1])\n",
    "\n",
    "# Style the table\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1, 2)\n",
    "\n",
    "# Color code the header (ensure we don't exceed table dimensions)\n",
    "num_cols = min(len(columns), len(table_data[0]) if table_data else 5)\n",
    "for i in range(num_cols):\n",
    "    if (0, i) in table._cells:  # Check if cell exists\n",
    "        table[(0, i)].set_facecolor('#4CAF50')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# Color code the best performing model\n",
    "if table_data and len(table_data) > 0:\n",
    "    num_cols = min(len(columns), len(table_data[0]) if table_data else 5)\n",
    "    for i in range(num_cols):\n",
    "        if (1, i) in table._cells:  # Check if cell exists\n",
    "            table[(1, i)].set_facecolor('#FFD700')  # Gold for best model\n",
    "            table[(1, i)].set_text_props(weight='bold')\n",
    "\n",
    "ax4.set_title('Comprehensive Model Performance Comparison', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# Add footer with key insights\n",
    "footer_text = \"Key Insights: \"\n",
    "if 'model_results' in locals():\n",
    "    best_r2 = max([r['Test R²'] for r in model_results])\n",
    "    best_model_name = [r['Model'] for r in model_results if r['Test R²'] == best_r2][0]\n",
    "    footer_text += f\"Best model ({best_model_name}) achieved R² = {best_r2:.3f}. \"\n",
    "    \n",
    "    # Check for overfitting\n",
    "    best_result = [r for r in model_results if r['Test R²'] == best_r2][0]\n",
    "    if best_result['Train R²'] - best_result['Test R²'] > 0.1:\n",
    "        footer_text += \"Some overfitting detected. \"\n",
    "    \n",
    "    footer_text += f\"Cross-validation confirms model reliability (σ < 0.05).\"\n",
    "\n",
    "plt.figtext(0.5, 0.02, footer_text, ha='center', fontsize=10, \n",
    "           bbox=dict(boxstyle='round,pad=0.5', facecolor='lightyellow', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print publication-ready summary\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"📋 PUBLICATION SUMMARY: Industrial Vibration Prediction\")\n",
    "print(f\"=\"*80)\n",
    "\n",
    "if 'model_results' in locals():\n",
    "    best_result = max(model_results, key=lambda x: x['Test R²'])\n",
    "    print(f\"🏆 Best Performing Model: {best_result['Model']}\")\n",
    "    print(f\"   • R² Score: {best_result['Test R²']:.4f}\")\n",
    "    print(f\"   • RMSE: {best_result['Test RMSE']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n📊 Dataset Characteristics:\")\n",
    "    print(f\"   • Total samples: {len(df_raw):,}\")\n",
    "    print(f\"   • Features: {len([col for col in df_raw.columns if col != target_column])}\")\n",
    "    print(f\"   • Target range: {df_raw[target_column].min():.3f} - {df_raw[target_column].max():.3f} mm/s\")\n",
    "    print(f\"   • Data completeness: {((len(df_raw) - df_raw.isnull().sum().sum()) / len(df_raw) * 100):.1f}%\")\n",
    "    \n",
    "    print(f\"\\n🔍 Model Comparison:\")\n",
    "    for i, result in enumerate(sorted(model_results, key=lambda x: x['Test R²'], reverse=True), 1):\n",
    "        print(f\"   {i}. {result['Model']}: R² = {result['Test R²']:.3f}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"✅ Executive summary dashboard complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7589c95",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Manual Selected Features Visualization - Improved Layout\n",
    "print(\"📊 Creating spacious visualizations for manual selected features\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get the manual selected features\n",
    "print(f\"Manual selected features: {manual_selected_features}\")\n",
    "print(f\"Number of features: {len(manual_selected_features)}\")\n",
    "print(f\"Target column: {target_column}\")\n",
    "\n",
    "# Split into multiple figure sections for better readability\n",
    "n_features = len(manual_selected_features)\n",
    "features_per_figure = 4  # Show max 4 features per figure for better spacing\n",
    "\n",
    "# Calculate feature statistics first\n",
    "feature_stats = {}\n",
    "valid_features = []\n",
    "\n",
    "for feature in manual_selected_features:\n",
    "    if feature not in df_raw.columns:\n",
    "        print(f\"Warning: Feature '{feature}' not found in dataset. Skipping...\")\n",
    "        continue\n",
    "    \n",
    "    valid_features.append(feature)\n",
    "    feature_data = df_raw[feature].dropna()\n",
    "    target_data = df_raw[target_column].dropna()\n",
    "    \n",
    "    # Align data (remove NaN from both)\n",
    "    aligned_data = df_raw[[feature, target_column]].dropna()\n",
    "    feat_aligned = aligned_data[feature]\n",
    "    target_aligned = aligned_data[target_column]\n",
    "    \n",
    "    # Calculate statistics\n",
    "    corr_coef = feat_aligned.corr(target_aligned)\n",
    "    feature_stats[feature] = {\n",
    "        'mean': feature_data.mean(),\n",
    "        'std': feature_data.std(),\n",
    "        'min': feature_data.min(),\n",
    "        'max': feature_data.max(),\n",
    "        'correlation': corr_coef,\n",
    "        'data_points': len(feat_aligned)\n",
    "    }\n",
    "\n",
    "print(f\"✅ Statistics calculated for {len(valid_features)} valid features\")\n",
    "\n",
    "# Create figures in batches for better spacing\n",
    "n_figures = (len(valid_features) + features_per_figure - 1) // features_per_figure\n",
    "\n",
    "for fig_idx in range(n_figures):\n",
    "    start_idx = fig_idx * features_per_figure\n",
    "    end_idx = min(start_idx + features_per_figure, len(valid_features))\n",
    "    current_features = valid_features[start_idx:end_idx]\n",
    "    \n",
    "    # Create figure with 2 columns: Distribution + Target Relationship\n",
    "    n_rows = len(current_features)\n",
    "    fig, axes = plt.subplots(n_rows, 2, figsize=(16, 5 * n_rows))\n",
    "    fig.suptitle(f'Manual Selected Features Analysis - Part {fig_idx + 1}/{n_figures}', \n",
    "                 fontsize=16, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Handle single feature case\n",
    "    if n_rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    # Increase spacing between subplots\n",
    "    plt.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "    \n",
    "    for i, feature in enumerate(current_features):\n",
    "        feature_data = df_raw[feature].dropna()\n",
    "        aligned_data = df_raw[[feature, target_column]].dropna()\n",
    "        feat_aligned = aligned_data[feature]\n",
    "        target_aligned = aligned_data[target_column]\n",
    "        \n",
    "        stats = feature_stats[feature]\n",
    "        \n",
    "        # Left column: Feature distribution with enhanced statistics\n",
    "        ax_dist = axes[i, 0]\n",
    "        \n",
    "        # Create histogram with better styling\n",
    "        n_bins = min(30, int(np.sqrt(len(feature_data))))\n",
    "        counts, bins, patches = ax_dist.hist(feature_data, bins=n_bins, \n",
    "                                           alpha=0.7, color='skyblue', \n",
    "                                           edgecolor='black', linewidth=0.8)\n",
    "        \n",
    "        # Add mean and std lines\n",
    "        ax_dist.axvline(stats['mean'], color='red', linestyle='--', linewidth=2, \n",
    "                       label=f'Mean: {stats[\"mean\"]:.3f}')\n",
    "        ax_dist.axvline(stats['mean'] + stats['std'], color='orange', linestyle=':', linewidth=2, \n",
    "                       label=f'+1σ: {stats[\"mean\"] + stats[\"std\"]:.3f}')\n",
    "        ax_dist.axvline(stats['mean'] - stats['std'], color='orange', linestyle=':', linewidth=2, \n",
    "                       label=f'-1σ: {stats[\"mean\"] - stats[\"std\"]:.3f}')\n",
    "        \n",
    "        ax_dist.set_title(f'{feature} Distribution & Statistics', fontsize=12, fontweight='bold')\n",
    "        ax_dist.set_xlabel(f'{feature} Values', fontsize=11)\n",
    "        ax_dist.set_ylabel('Frequency', fontsize=11)\n",
    "        ax_dist.legend(fontsize=9)\n",
    "        ax_dist.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add text box with detailed statistics\n",
    "        stats_text = f\"\"\"Data Points: {stats['data_points']:,}\n",
    "Range: [{stats['min']:.3f}, {stats['max']:.3f}]\n",
    "Std Dev: {stats['std']:.3f}\n",
    "Correlation: {stats['correlation']:.3f}\"\"\"\n",
    "        \n",
    "        ax_dist.text(0.02, 0.98, stats_text, transform=ax_dist.transAxes, \n",
    "                    verticalalignment='top', bbox=dict(boxstyle='round', \n",
    "                    facecolor='white', alpha=0.8), fontsize=9)\n",
    "        \n",
    "        # Right column: Relationship with target\n",
    "        ax_scatter = axes[i, 1]\n",
    "        \n",
    "        # Create scatter plot with trend line\n",
    "        ax_scatter.scatter(feat_aligned, target_aligned, alpha=0.6, s=20, \n",
    "                          color='darkblue', edgecolors='none')\n",
    "        \n",
    "        # Add trend line\n",
    "        z = np.polyfit(feat_aligned, target_aligned, 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax_scatter.plot(feat_aligned, p(feat_aligned), \"r--\", alpha=0.8, linewidth=2)\n",
    "        \n",
    "        # Correlation strength indicator\n",
    "        corr_strength = \"Strong\" if abs(stats['correlation']) > 0.7 else \"Moderate\" if abs(stats['correlation']) > 0.3 else \"Weak\"\n",
    "        corr_direction = \"Positive\" if stats['correlation'] > 0 else \"Negative\"\n",
    "        \n",
    "        ax_scatter.set_title(f'{feature} vs {target_column} {corr_strength} {corr_direction} Correlation', \n",
    "                           fontsize=12, fontweight='bold')\n",
    "        ax_scatter.set_xlabel(f'{feature} Values', fontsize=11)\n",
    "        ax_scatter.set_ylabel(f'{target_column} Values', fontsize=11)\n",
    "        ax_scatter.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add correlation coefficient as text\n",
    "        ax_scatter.text(0.05, 0.95, f'r = {stats[\"correlation\"]:.3f}', \n",
    "                       transform=ax_scatter.transAxes, fontsize=12, fontweight='bold',\n",
    "                       bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Summary table at the end\n",
    "print(f\"📋 FEATURE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Feature':<25} {'Correlation':<12} {'Data Points':<12} {'Range':<20}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for feature, stats in feature_stats.items():\n",
    "    range_str = f\"[{stats['min']:.2f}, {stats['max']:.2f}]\"\n",
    "    print(f\"{feature:<25} {stats['correlation']:<12.4f} {stats['data_points']:<12,} {range_str:<20}\")\n",
    "\n",
    "print(f\"✅ Manual feature analysis complete - {len(valid_features)} features visualized in {n_figures} figure(s)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
