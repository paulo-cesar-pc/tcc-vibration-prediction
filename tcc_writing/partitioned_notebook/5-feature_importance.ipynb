{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eafb7a70",
   "metadata": {},
   "source": [
    "## 7. Feature Importance\n",
    "**Purpose**: Identify the most predictive features using machine learning techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89020834",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Selection Functions - Define before using\n",
    "def select_top_k_features(X, y, feature_names, k=20):\n",
    "    \"\"\"Select top K features based on Random Forest importance\"\"\"\n",
    "    rf = RandomForestRegressor(n_estimators=25, max_depth=4, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    importance_scores = rf.feature_importances_\n",
    "    feature_importance = list(zip(feature_names, importance_scores))\n",
    "    feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    selected_features = [f[0] for f in feature_importance[:k]]\n",
    "    selected_indices = [feature_names.index(f) for f in selected_features]\n",
    "    \n",
    "    return selected_features, selected_indices\n",
    "\n",
    "def select_by_cumulative_importance(X, y, feature_names, threshold=0.8):\n",
    "    \"\"\"Select features that contribute to X% of cumulative importance\"\"\"\n",
    "    rf = RandomForestRegressor(n_estimators=25, max_depth=4, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    importance_scores = rf.feature_importances_\n",
    "    feature_importance = list(zip(feature_names, importance_scores))\n",
    "    feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    cumulative_importance = 0\n",
    "    selected_features = []\n",
    "    \n",
    "    for feature, importance in feature_importance:\n",
    "        selected_features.append(feature)\n",
    "        cumulative_importance += importance\n",
    "        if cumulative_importance >= threshold:\n",
    "            break\n",
    "    \n",
    "    selected_indices = [feature_names.index(f) for f in selected_features]\n",
    "    return selected_features, selected_indices\n",
    "\n",
    "def select_statistical_features(X, y, feature_names, k=20):\n",
    "    \"\"\"Select features using statistical tests (f_regression)\"\"\"\n",
    "    selector = SelectKBest(score_func=f_regression, k=k)\n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "    \n",
    "    selected_indices = selector.get_support(indices=True)\n",
    "    selected_features = [feature_names[i] for i in selected_indices]\n",
    "    \n",
    "    return selected_features, selected_indices\n",
    "\n",
    "print(\"‚úÖ Feature selection functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d918063",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Importance Analysis using Random Forest\n",
    "print(\"üéØ Feature Importance Analysis\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Prepare data for importance analysis\n",
    "X_temp, _, y_temp, _ = prepare_model_data(df_features, target_column, test_size=0.3)\n",
    "\n",
    "# Use only a subset of data for faster training\n",
    "sample_size = min(5000, len(X_temp))  # Limit to 5000 samples max\n",
    "if len(X_temp) > sample_size:\n",
    "    from sklearn.utils import resample\n",
    "    X_temp, y_temp = resample(X_temp, y_temp, n_samples=sample_size, random_state=42)\n",
    "\n",
    "print(f\"üìä Importance Analysis Setup:\")\n",
    "print(f\"  ‚Ä¢ Features for analysis: {X_temp.shape[1]}\")\n",
    "print(f\"  ‚Ä¢ Samples for training: {X_temp.shape[0]:,}\")\n",
    "print(f\"  ‚Ä¢ Target variable: {target_column}\")\n",
    "\n",
    "# Train Random Forest for feature importance (using a subset for speed)\n",
    "print(f\"\\nüå≤ Training Random Forest for Feature Importance...\")\n",
    "rf_importance = RandomForestRegressor(\n",
    "    n_estimators=50,        # Reduced from 100 for speed\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    max_depth=8,           # Reduced from 10\n",
    "    min_samples_split=10,  # Added to prevent overfitting\n",
    "    min_samples_leaf=5     # Added to speed up training\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "rf_importance.fit(X_temp, y_temp)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_temp.columns,\n",
    "    'importance': rf_importance.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"‚úÖ Random Forest trained successfully\")\n",
    "print(f\"  ‚Ä¢ Model R¬≤ score: {rf_importance.score(X_temp, y_temp):.3f}\")\n",
    "print(f\"  ‚Ä¢ Feature importance calculated for {len(feature_importance)} features\")\n",
    "\n",
    "# Display top features\n",
    "print(f\"\\nüèÜ Top 20 Most Important Features:\")\n",
    "print(f\"{'Rank':<4} {'Feature':<50} {'Importance':<12} {'Type'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, (_, row) in enumerate(feature_importance.head(20).iterrows(), 1):\n",
    "    feature = row['feature']\n",
    "    importance = row['importance']\n",
    "    \n",
    "    # Determine feature type\n",
    "    if '_rolling_mean_' in feature:\n",
    "        feat_type = 'Rolling Mean'\n",
    "    elif '_rolling_std_' in feature:\n",
    "        feat_type = 'Rolling Std'\n",
    "    elif feature in ['hour', 'day_of_week', 'month']:\n",
    "        feat_type = 'Temporal'\n",
    "    else:\n",
    "        feat_type = 'Original'\n",
    "    \n",
    "    print(f\"{i:<4} {feature[:48]:<50} {importance:<12.4f} {feat_type}\")\n",
    "\n",
    "# Calculate importance by feature type\n",
    "importance_by_type = {}\n",
    "for feat_type in ['Original', 'Rolling Mean', 'Rolling Std', 'Temporal']:\n",
    "    if feat_type == 'Rolling Mean':\n",
    "        mask = feature_importance['feature'].str.contains('_rolling_mean_')\n",
    "    elif feat_type == 'Rolling Std':\n",
    "        mask = feature_importance['feature'].str.contains('_rolling_std_')\n",
    "    elif feat_type == 'Temporal':\n",
    "        mask = feature_importance['feature'].isin(['hour', 'day_of_week', 'month'])\n",
    "    else:  # Original\n",
    "        mask = ~(feature_importance['feature'].str.contains('_rolling_') | \n",
    "                feature_importance['feature'].isin(['hour', 'day_of_week', 'month']))\n",
    "    \n",
    "    if mask.any():\n",
    "        importance_by_type[feat_type] = {\n",
    "            'total_importance': feature_importance[mask]['importance'].sum(),\n",
    "            'avg_importance': feature_importance[mask]['importance'].mean(),\n",
    "            'count': mask.sum(),\n",
    "            'top_feature': feature_importance[mask].iloc[0]['feature'] if mask.any() else 'None'\n",
    "        }\n",
    "\n",
    "print(f\"\\nüìä Feature Importance by Type:\")\n",
    "print(f\"{'Type':<15} {'Count':<7} {'Total Imp':<11} {'Avg Imp':<10} {'Top Feature'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for feat_type, stats in importance_by_type.items():\n",
    "    print(f\"{feat_type:<15} {stats['count']:<7} {stats['total_importance']:<11.4f} {stats['avg_importance']:<10.4f} {stats['top_feature'][:25]}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Feature importance analysis complete\")\n",
    "\n",
    "# Store results for next steps\n",
    "importance_results = {\n",
    "    'feature_importance_df': feature_importance,\n",
    "    'model_r2': rf_importance.score(X_temp, y_temp),\n",
    "    'importance_by_type': importance_by_type\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cd469f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Importance Visualization\n",
    "print(\"\\nüìä Feature Importance Visualization\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Feature Importance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Top 15 features bar plot\n",
    "top_15 = feature_importance.head(15)\n",
    "axes[0, 0].barh(range(len(top_15)), top_15['importance'])\n",
    "axes[0, 0].set_yticks(range(len(top_15)))\n",
    "axes[0, 0].set_yticklabels([f[:30] + '...' if len(f) > 30 else f for f in top_15['feature']])\n",
    "axes[0, 0].set_xlabel('Importance')\n",
    "axes[0, 0].set_title('Top 15 Most Important Features')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].invert_yaxis()\n",
    "\n",
    "# 2. Importance by feature type\n",
    "types = list(importance_by_type.keys())\n",
    "total_importances = [importance_by_type[t]['total_importance'] for t in types]\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen', 'gold']\n",
    "\n",
    "bars = axes[0, 1].bar(types, total_importances, color=colors[:len(types)], alpha=0.7)\n",
    "axes[0, 1].set_title('Total Importance by Feature Type')\n",
    "axes[0, 1].set_ylabel('Total Importance')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, total_importances):\n",
    "    height = bar.get_height()\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + 0.001,\n",
    "                   f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. Cumulative importance\n",
    "cumulative_importance = feature_importance['importance'].cumsum()\n",
    "axes[1, 0].plot(range(1, len(cumulative_importance) + 1), cumulative_importance)\n",
    "axes[1, 0].axhline(y=0.8, color='red', linestyle='--', alpha=0.7, label='80% threshold')\n",
    "axes[1, 0].axhline(y=0.9, color='orange', linestyle='--', alpha=0.7, label='90% threshold')\n",
    "axes[1, 0].set_xlabel('Number of Features')\n",
    "axes[1, 0].set_ylabel('Cumulative Importance')\n",
    "axes[1, 0].set_title('Cumulative Feature Importance')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Find how many features needed for 80% and 90% importance\n",
    "features_for_80 = (cumulative_importance >= 0.8).idxmax() + 1\n",
    "features_for_90 = (cumulative_importance >= 0.9).idxmax() + 1\n",
    "\n",
    "# 4. Average importance by feature type\n",
    "avg_importances = [importance_by_type[t]['avg_importance'] for t in types]\n",
    "axes[1, 1].bar(types, avg_importances, color=colors[:len(types)], alpha=0.7)\n",
    "axes[1, 1].set_title('Average Importance by Feature Type')\n",
    "axes[1, 1].set_ylabel('Average Importance')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, value) in enumerate(zip(axes[1, 1].patches, avg_importances)):\n",
    "    height = bar.get_height()\n",
    "    axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 0.0001,\n",
    "                   f'{value:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analysis insights\n",
    "print(f\"\\nüéØ Key Feature Importance Insights:\")\n",
    "print(f\"  ‚Ä¢ Most important feature: {feature_importance.iloc[0]['feature']}\")\n",
    "print(f\"    - Importance: {feature_importance.iloc[0]['importance']:.4f}\")\n",
    "print(f\"    - Type: {'Rolling Mean' if '_rolling_mean_' in feature_importance.iloc[0]['feature'] else 'Original'}\")\n",
    "\n",
    "print(f\"\\nüìä Feature Selection Recommendations:\")\n",
    "print(f\"  ‚Ä¢ Features needed for 80% importance: {features_for_80}\")\n",
    "print(f\"  ‚Ä¢ Features needed for 90% importance: {features_for_90}\")\n",
    "print(f\"  ‚Ä¢ Total features available: {len(feature_importance)}\")\n",
    "\n",
    "# Feature type performance\n",
    "best_type = max(importance_by_type.items(), key=lambda x: x[1]['avg_importance'])\n",
    "print(f\"\\nüèÜ Best performing feature type:\")\n",
    "print(f\"  ‚Ä¢ Type: {best_type[0]}\")\n",
    "print(f\"  ‚Ä¢ Average importance: {best_type[1]['avg_importance']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Total contribution: {best_type[1]['total_importance']:.4f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Feature importance visualization complete - ready for feature selection\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
